{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Extraction and Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "To prepare your environment, you need to install some packages and enter credentials for the Watson services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Install the necessary packages\n",
    "\n",
    "You need the latest versions of these packages:                                                                                                                                     \n",
    "Watson Developer Cloud: a client library for Watson services.                                                                                                                        \n",
    "NLTK: leading platform for building Python programs to work with human language data.                                                                                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the Watson Developer Cloud package: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade watson-developer-cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install IBM Cloud Object Storage Client: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install ibm-cos-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now restart the kernel by choosing Kernel > Restart. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Import packages and libraries\n",
    "Import the packages and libraries that you'll use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import watson_developer_cloud\n",
    "from watson_developer_cloud import NaturalLanguageUnderstandingV1\n",
    "from watson_developer_cloud.natural_language_understanding_v1 \\\n",
    "  import Features, EntitiesOptions, KeywordsOptions\n",
    "    \n",
    "import ibm_boto3\n",
    "from botocore.client import Config\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import datetime\n",
    "from nltk import word_tokenize,sent_tokenize,ne_chunk\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "try:\n",
    "    import Image\n",
    "except ImportError:\n",
    "    from PIL import Image\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "Add configurable items of the notebook below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Add your service credentials from IBM Cloud for the Watson services\n",
    "You must create a Watson Natural Language Understanding service on IBM Cloud. Create a service for Natural Language Understanding (NLU). Insert the username and password values for your NLU in the following cell. Do not change the values of the version fields.\n",
    "Run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
    "    version='2018-03-23',\n",
    "    username=\"9d8eddab-da9f-454c-a1cc-a02ed8c2fe92\",\n",
    "    password=\"A4JHnZoZ1Wwt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Add your service credentials for Object Storage\n",
    "You must create Object Storage service on IBM Cloud. To access data in a file in Object Storage, you need the Object Storage authentication credentials. Insert the Object Storage authentication credentials as credentials_1 in the following cell after removing the current contents in the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "# @hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "# @hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "credentials_1 = {\n",
    "    'IBM_API_KEY_ID': 'Q6atq-m6UyXDxpWggSaqSKDwG0uXEtRvYQ6Kuidc-2tv',\n",
    "    'IAM_SERVICE_ID': 'iam-ServiceId-e60f3d32-9fc3-450b-900e-47795b493d3c',\n",
    "    'ENDPOINT': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n",
    "    'IBM_AUTH_ENDPOINT': 'https://iam.ng.bluemix.net/oidc/token',\n",
    "    'BUCKET': 'trialdocclassifierd85dc7d8d1b44e2f8d783eb499e697ba',\n",
    "    'FILE': 'purchase_agreement.txt'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Global Variables\n",
    "Add global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampleText1='purchase_agreement.txt'\n",
    "sampleText2='Rental_agreement.txt'\n",
    "sampleConfigFileName='config_entity_extract.txt'\n",
    "sampleConfigFileName1= 'config_legaldocs.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Configure and download required NLTK packages\n",
    "Download the 'punkt' and 'averaged_perceptron_tagger' NLTK packages for POS tagging usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /gpfs/fs01/user/sa6d-\n",
      "[nltk_data]     86c4a368f35c52-bd18af67f60c/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /gpfs/fs01/user/sa6d-\n",
      "[nltk_data]     86c4a368f35c52-bd18af67f60c/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Persistence and Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Configure Object Storage Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cos = ibm_boto3.client('s3',\n",
    "                    ibm_api_key_id=credentials_1['IBM_API_KEY_ID'],\n",
    "                    ibm_service_instance_id=credentials_1['IAM_SERVICE_ID'],\n",
    "                    ibm_auth_endpoint=credentials_1['IBM_AUTH_ENDPOINT'],\n",
    "                    config=Config(signature_version='oauth'),\n",
    "                    endpoint_url=credentials_1['ENDPOINT'])\n",
    "\n",
    "def get_file(filename):\n",
    "    '''Retrieve file from Cloud Object Storage'''\n",
    "    fileobject = cos.get_object(Bucket=credentials_1['BUCKET'], Key=filename)['Body']\n",
    "    return fileobject\n",
    "\n",
    "def load_string(fileobject):\n",
    "    '''Load the file contents into a Python string'''\n",
    "    text = fileobject.read()\n",
    "    return text\n",
    "\n",
    "def put_file(filename, filecontents):\n",
    "    '''Write file to Cloud Object Storage'''\n",
    "    resp = cos.put_object(Bucket=credentials_1['BUCKET'], Key=filename, Body=filecontents)\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Input Data\n",
    "Read the data file for entity extraction from Object Store                                                                                                                               \n",
    "Read the configuration file for augumented entity-value pairs from Object Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿PURCHASE AGREEMENT\r\n",
      "\r\n",
      "THIS IS A LEGALLY BINDING CONTRACT BETWEEN\r\n",
      "Borrower AND Owner.\r\n",
      "IF YOU DO NOT UNDERSTAND IT, SEEK LEGAL ADVICE.\r\n",
      "\r\n",
      "1. PARTIES TO CONTRACT - PROPERTY. Borrower and Owner acknowledge that Broker is ABC\r\n",
      "is not the limited agent of both parties to this transaction as outlined in Section III of the Agency\r\n",
      "Agreement Addendum as authorized by Borrower and Owner.\r\n",
      "\r\n",
      ", XYZ hereinafter referred to as\r\n",
      "\r\n",
      "Borrower, offers and agrees to purchase from , UVW\r\n",
      "hereinafter referred to as Owner, upon the tenns and conditions set forth, the property legally described as:\r\n",
      "\r\n",
      "also known as\r\n",
      "\r\n",
      "2. EARNEST MONEY DEPOSIT. Earnest Money in the amount of ($ )\r\n",
      "DOLLARS Cash Check ,\r\n",
      "unless otherwise noted herein, shall be deposited into the trust account of the listing selling\r\n",
      "\r\n",
      "broker on the next legal banking day after acceptance of this offer.\r\n",
      "\r\n",
      "Other earnest money provisions:\r\n",
      "\r\n",
      "3. PURCHASE PRICE. The total purchase price is to be ($ )\r\n",
      "DOLLARS\r\n",
      "\r\n",
      "After earnest money herein is credited, the remaining balance is to be paid by Borrower at closing.\r\n",
      "\r\n",
      "4. F INANCING.\r\n",
      "‘Jew Mortgage. This offer is contingent upon Borrower obtaining a new\r\n",
      "\r\n",
      "VA, FHA, SDHDA, Conventional, or type of loan.\r\n",
      "A letter of Borrower’s loan status from\r\n",
      "\r\n",
      "is attached or will be delivered by (date).\r\n",
      "\r\n",
      "Within T legal banking days after acceptance of this Agreement, Borrower will make application\r\n",
      "for and diligently and in good faith endeavor to secure a new loan, pay all application fees, and to sign\r\n",
      "all financing documents without delay. Borrower reserves the right to obtain alternative financing as\r\n",
      "long as there are no increased costs to Owner.\r\n",
      "\r\n",
      "Assumption. See attached Addendum.\r\n",
      "Contract for Deed/Private Mortgage. See attached Addendum.\r\n",
      "\r\n",
      "Cash. This is a cash offer. The remaining balance of “.6 will be paid at closing by\r\n",
      "certified check. A letter of veriﬁcation from\r\n",
      "\r\n",
      "regarding the availability of funds is attached will be delivered by (date) or\r\n",
      "this agreement, at the option of Owner without notice to Borrower may be voided.\r\n",
      "\r\n",
      "INITIALS: Borrower / Owner /\r\n",
      "\r\n",
      "Page 1 of 5\r\n",
      "SDREC.RESIDENTIALPURCHASEAGREEMENT.201 1\n",
      "()\n",
      "Residential Lease Agreement\r\n",
      "\r\n",
      "This Residential Lease Agreement is made between the Landlord ABC\r\n",
      "and the Tenant XYZ on this date\r\n",
      "\r\n",
      "The Landlord hereby agrees to rent the Premises to the Tenant and Tenant hereby agrees to rent the\r\n",
      "Premises from the Landlord. The Premises is described as follows:\r\n",
      "\r\n",
      "Street Address:\r\n",
      "\r\n",
      "Premises Description:\r\n",
      "\r\n",
      "1. TERM:\r\n",
      "The Lease term shall be as follows (choose one):\r\n",
      "\r\n",
      "[] Fixed term lease beginning on and ending on for a total period\r\n",
      "of months.\r\n",
      "\r\n",
      "[] Month to month lease beginning on\r\n",
      "\r\n",
      "2. RENT:\r\n",
      "\r\n",
      "The Tenant agrees to pay the Landlord an amount of $ per month as rent on or before\r\n",
      "the day of each month.\r\n",
      "\r\n",
      "If rent due is not paid on of before the day of the month, Tenant agrees to pay a late charge of $\r\n",
      "plus an additional late charge of $ per day until the rent is paid in\r\n",
      "\r\n",
      "full.\r\n",
      "3. SECURITY DEPOSIT:\r\n",
      "\r\n",
      "The Tenant shall deposit an amount of $ to be held by the Landlord as security\r\n",
      "deposit. This deposit shall be refunded to the Tenant upon termination of this Lease after deducting for\r\n",
      "any of the following: default of rent payment, loss or damage to the Premises or its furnishings, any\r\n",
      "required cleaning of the Premises and for any other reason allowed by law.\r\n",
      "\r\n",
      "4. USE OF PREMISES:\r\n",
      "\r\n",
      "The Premises shall be occupied only by the Tenant and the following occupants:\r\n",
      "\r\n",
      "The Tenant shall use the Premises for residential purposes only and may not use it for any other purpose\r\n",
      "with the written consent of the Landlord. The Tenant may not sublet this Premises or assign this Lease to\r\n",
      "any other persons without the written consent of the Landlord.\n"
     ]
    }
   ],
   "source": [
    "text1= load_string(get_file(sampleText1))\n",
    "print(text1)\n",
    "print()\n",
    "text2 = load_string(get_file(sampleText2))\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "\t\"configuration\":{\r\n",
      "\t\t\"class\":{\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t\"stages\" : [\r\n",
      "\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\"name\": \"Intro\",\r\n",
      "\t\t\t\t\t\"steps\": [\r\n",
      "\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\t\"type\":\"text\",\t\r\n",
      "\t\t\t\t\t\t\"tag\":\"Landlord\",\r\n",
      "\t\t\t\t\t\t\"regex\": \"Chunk: {<NNP> <NNP> (<IN> <VBP>)?}\"\r\n",
      "\t\t\t\t\t},\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\t\"type\":\"text\",\t\r\n",
      "\t\t\t\t\t\t\"tag\":\"Tenant\",\r\n",
      "\t\t\t\t\t\t\"regex\": \"Chunk: {<NNP> <NNP> (<IN> <VBP>)?}\"\r\n",
      "\t\t\t\t\t},\r\n",
      "\t\t\t\t\t{\r\n",
      "\r\n",
      "\t\t\t\t\t\t\"type\":\"date\",\r\n",
      "\t\t\t\t\t\t\"tag\":\"Date\",\r\n",
      "\t\t\t\t\t\t\"regex1\":\"\\\\d+/\\\\d+/\\\\d+\"\r\n",
      "\t\t\t\t\t}\r\n",
      "\r\n",
      "\t\t\t\t\t]\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\t},\r\n",
      "\t\t\t\t\t\r\n",
      "\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\"name\": \"Term\",\r\n",
      "\t\t\t\t\t\"steps\":[\r\n",
      "\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\t\"term_type\": \"Fixed\",\r\n",
      "\t\t\t\t\t\t\"type\":\"date\",\r\n",
      "\t\t\t\t\t\t\"tag\":\"beginning on\",\r\n",
      "\t\t\t\t\t\t\"regex\":\"\\\\d+/\\\\d+/\\\\d+\"\r\n",
      "\t\t\t\t\t},\r\n",
      "\t\t\t\t\t\r\n",
      "\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\t\"term_type\": \"Fixed\",\r\n",
      "\t\t\t\t\t\t\"type\":\"date\",\r\n",
      "\t\t\t\t\t\t\"tag\":\"ending on\",\r\n",
      "\t\t\t\t\t\t\"regex\":\"\\\\d+/\\\\d+/\\\\d+\"\r\n",
      "\t\t\t\t\t},\r\n",
      "\t\t\t\t\t\r\n",
      "\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\t\"term_type\": \"Month\",\r\n",
      "\t\t\t\t\t\t\"type\":\"date\",\r\n",
      "\t\t\t\t\t\t\"tag\":\"beginning on\",\r\n",
      "\t\t\t\t\t\t\"regex\":\"\\\\d+/\\\\d+/\\\\d+\"\r\n",
      "\t\t\t\t\t}\r\n",
      "\t\t\t\t\t]\r\n",
      "\t\t\t\t\t\r\n",
      "\t\t\t\t\t\r\n",
      "\t\t\t\t\t},\r\n",
      "\t\t\t\t\t\r\n",
      "\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\"name\": \"Rent\",\r\n",
      "\t\t\t\t\t\"steps\":[\r\n",
      "\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\t\"type\":\"amount\",\r\n",
      "\t\t\t\t\t\t\"tag\": \"Rental amt\",\r\n",
      "\t\t\t\t\t\t\"regex\":\"\\\\$\\\\s+\\\\d+\"\r\n",
      "\t\t\t\t\t}\r\n",
      "\t\t\t\t\t]\r\n",
      "\t\t\t\t\t\r\n",
      "\t\t\t\t\t\r\n",
      "\t\t\t\t\t},\r\n",
      "\r\n",
      "\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\t\"name\": \"Parties to Contract\",\r\n",
      "\t\t\t\t\t\t\"steps\": [\r\n",
      "\t\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\t\t\"type\":\"text\",\r\n",
      "\t\t\t\t\t\t\t\"tag\": \"Broker\",\r\n",
      "\t\t\t\t\t\t\t\"regex\": \"Chunk: {<NNP> <VBZ> <NNP>}\"\r\n",
      "\t\t\t\t\t\t},\r\n",
      "\t\t\t\t\t\t\r\n",
      "\t\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\t\t\"type\":\"text\",\r\n",
      "\t\t\t\t\t\t\t\"tag\": \"borrower\",\r\n",
      "\t\t\t\t\t\t\t\"regex\": \"Chunk: {<NNP> <NN> <VBD> <TO> <IN> <NNP>}\"\r\n",
      "\t\t\t\t\t\t},\r\n",
      "\t\t\t\t\t\t\r\n",
      "\t\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\t\t\"type\":\"text\",\r\n",
      "\t\t\t\t\t\t\t\"tag\": \"Owner\",\r\n",
      "\t\t\t\t\t\t\t\"regex\": \"Chunk: {<NNP> <NN> <VBD> <TO> <IN> <NNP>}\"\r\n",
      "\t\t\t\t\t\t}\r\n",
      "\t\t\t\t\t\t]\r\n",
      "\t\t\t\t\t\t\r\n",
      "\t\t\t\t\t}\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\t]\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t\t\r\n",
      "\t\t}\r\n",
      "\t}\r\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "config = load_string(get_file(sampleConfigFileName))\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "\t\"configuration\":{\r\n",
      "\t\t\"classification\":{\r\n",
      "\t\t\t\"stages\":[\r\n",
      "\t\t\t\t{\r\n",
      "\t\t\t\t\t\"doctype\":\"Rental\",\r\n",
      "\t\t\t\t\t\"entities\":[\r\n",
      "\t\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\t\t\"tag\":\"Lease Term\",\r\n",
      "\t\t\t\t\t\t\t\"text\":\"lease term\"\r\n",
      "\t\t\t\t\t\t},\r\n",
      "\t\t\t\t\t\t\r\n",
      "\t\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\t\t\"tag\":\"Rent\",\r\n",
      "\t\t\t\t\t\t\t\"text\":\"Rent\"\r\n",
      "\t\t\t\t\t\t},\r\n",
      "\t\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\t\t\"tag\":\"Security Deposit\",\r\n",
      "\t\t\t\t\t\t\t\"text\":\"Security Deposit\"\r\n",
      "\t\t\t\t\t\t}\r\n",
      "\t\t\t\t\t\r\n",
      "\t\t\t\t\t]\r\n",
      "\t\t\t\t},\r\n",
      "\t\t\t\t{\r\n",
      "\t\t\t\t\t\"doctype\":\"Purchase\",\r\n",
      "\t\t\t\t\t\"entities\":[\r\n",
      "\t\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\t\t\"tag\":\"PARTIES TO CONTRACT - PROPERTY\",\r\n",
      "\t\t\t\t\t\t\t\"text\":\"PARTIES TO CONTRACT - PROPERTY\"\r\n",
      "\t\t\t\t\t\t},\r\n",
      "\t\t\t\t\t\t\r\n",
      "\t\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\t\t\"tag\":\"EARNEST MONEY DEPOSIT\",\r\n",
      "\t\t\t\t\t\t\t\"text\":\"EARNEST MONEY DEPOSIT\"\r\n",
      "\t\t\t\t\t\t},\r\n",
      "\t\t\t\t\t\t{\r\n",
      "\t\t\t\t\t\t\t\"tag\":\"PURCHASE PRICE\",\r\n",
      "\t\t\t\t\t\t\t\"text\":\"PURCHASE PRICE\"\r\n",
      "\t\t\t\t\t\t}\r\n",
      "\t\t\t\t\t\r\n",
      "\t\t\t\t\t]\r\n",
      "\t\t\t\t}\r\n",
      "\t\t\t\t\r\n",
      "\t\t\t]\r\n",
      "\t\t\r\n",
      "\t\t}\r\n",
      "\t\r\n",
      "\t}\r\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "config1 = load_string(get_file(sampleConfigFileName1))\n",
    "print(config1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Entity Extraction\n",
    "Extract required entities present in the document and augment the response to NLU's results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Entites Extracted by Watson NLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze_using_NLU(analysistext):\n",
    "    \"\"\" Call Watson Natural Language Understanding service to obtain analysis results.\n",
    "    \"\"\"\n",
    "    response = natural_language_understanding.analyze( \n",
    "        text=analysistext,\n",
    "        features=Features(keywords=KeywordsOptions()))\n",
    "    response = [r['text'] for r in response['keywords']]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Extract Entity-Value \n",
    "Custom entity extraction utlity fucntions for augumenting the results of Watson NLU API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def POS_tagging(text):\n",
    "    \"\"\" Generate Part of speech tagging of the text.\n",
    "    \"\"\"\n",
    "    text=text.decode(\"utf-8\")\n",
    "    sent = re.sub(r'\\n',' ',text)\n",
    "    words = nltk.word_tokenize(sent)\n",
    "    POSofText = nltk.tag.pos_tag(words)\n",
    "    return POSofText\n",
    "\n",
    "\n",
    "entval= dict()\n",
    "def text_extract(reg, tag,text):\n",
    "    \"\"\" Use Chunking to extract text from sentence\n",
    "    \"\"\"\n",
    "    entities = list()\n",
    "    chunkParser= nltk.RegexpParser(reg)\n",
    "    chunked= chunkParser.parse(POS_tagging(text))\n",
    "    #print(chunked)\n",
    "    for subtree in chunked.subtrees():\n",
    "        if subtree.label() == 'Chunk':\n",
    "            entities.append(subtree.leaves())\n",
    "    #print(entities)\n",
    "    for i in range(len(entities)):\n",
    "        for j in range(len(entities[i])):\n",
    "            #print(entities[i][j])\n",
    "            if tag.strip() in entities[i][j][0]:\n",
    "                #print(entities[i])\n",
    "                entval.update({tag: find_NNP(entities[i],tag)})\n",
    "    return entval\n",
    "\n",
    "\n",
    "def find_NNP(ent, tag):\n",
    "    \"\"\" Find NNP POS tags\n",
    "    \"\"\"\n",
    "    e= ent\n",
    "    for i in range(len(e)):\n",
    "        if (tag not in e[i]) and (e[i][1] == 'NNP'):\n",
    "            return e[i][0]\n",
    "\n",
    "\n",
    "\n",
    "def checkValid(date):\n",
    "    #f= datetime.datetime.strftime(date)\n",
    "    try:\n",
    "        datetime.datetime.strptime(date.strip(),\"%d/%m/%Y\")\n",
    "        return 1\n",
    "    except ValueError as err:\n",
    "        print(err)\n",
    "        return 0\n",
    "    \n",
    "def date_extract(reg, tag, text, stage_name):\n",
    "    #print(reg)\n",
    "    d= dict()\n",
    "    dates=re.findall(tag.lower()+' '+reg,text.lower())\n",
    "    print(dates)\n",
    "    temp= dates[0].strip(tag.lower())\n",
    "    ret= checkValid(temp)\n",
    "    if ret == 1:\n",
    "        d.update({tag.lower():temp})\n",
    "    print(d)\n",
    "\n",
    "def amt_extract(reg,tag,text):\n",
    "    a= dict()\n",
    "    amt= re.findall(reg,text)\n",
    "    print(amt)\n",
    "    \n",
    "entities_req= list()\n",
    "def entities_required(text,step, types):\n",
    "    \"\"\" Extracting entities required from configuration file\n",
    "    \"\"\"\n",
    "    configjson= json.loads(config)\n",
    "    for i in range(len(step)):\n",
    "        if step[i]['type'] == types:\n",
    "            entities_req.append(str(step[i]['tag']))\n",
    "            #entities_req.append([c['tag'] for c in configjson['configuration']['class'][i]['steps'][j]])\n",
    "    return entities_req\n",
    "\n",
    "# entlist= list()\n",
    "def extract_entities(config,text):\n",
    "    \"\"\" Extracts entity-value pairs\n",
    "    \"\"\"\n",
    "    configjson= json.loads(config)\n",
    "    #print(configjson)\n",
    "    #print(configjson['configuration']['class'][0]['steps'][0]['entity'][0]['tag'])\n",
    "    classes=configjson['configuration']['class']\n",
    "    #for i in range(len(classes)):\n",
    "    stages= classes['stages']\n",
    "    for j in range(len(stages)):\n",
    "        if stages[j]['name']=='Intro':\n",
    "            steps= stages[j]['steps']\n",
    "            for k in range(len(steps)):\n",
    "                if steps[k]['type'] == 'text':\n",
    "                        #temp=entities_required(text,steps,steps[k]['type'])\n",
    "                            #print(temp)\n",
    "                    ent = text_extract(steps[k]['regex'],steps[k]['tag'],text)\n",
    "                #elif steps[k]['type'] == 'date':\n",
    "                    #dates= date_extract(steps[k]['regex1'],steps[k]['tag'],text, stages[j]['name'])\n",
    "        elif stages[j]['name']=='Parties to Contract':\n",
    "            steps= stages[j]['steps']\n",
    "            for k in range(len(steps)):\n",
    "                if steps[k]['type'] == 'text':\n",
    "                        #temp=entities_required(text,steps,steps[k]['type'])\n",
    "                    ent = text_extract(steps[k]['regex'],steps[k]['tag'],text)\n",
    "    \n",
    "    return ent\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'Broker': u'ABC', u'Owner': u'UVW'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_entities(config, text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Document Classification\n",
    "Classify documents based on entities extracted from the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[u'lease term', u'Rental'],\n",
       "  [u'Rent', u'Rental'],\n",
       "  [u'Security Deposit', u'Rental']],\n",
       " [[u'PARTIES TO CONTRACT - PROPERTY', u'Purchase'],\n",
       "  [u'EARNEST MONEY DEPOSIT', u'Purchase'],\n",
       "  [u'PURCHASE PRICE', u'Purchase']]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entities_required_classification(text,config):\n",
    "    \"\"\" Extracting entities from configuration file\n",
    "    \"\"\"\n",
    "    entities_req= list()\n",
    "    configjson= json.loads(config)\n",
    "    for stages in configjson['configuration']['classification']['stages']:\n",
    "        class_req= stages['doctype']\n",
    "        entities_req.append([[c['text'],class_req] for c in stages['entities']])\n",
    "    return entities_req\n",
    "#entities_required_classification(text2,config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_text(text, entities,config):\n",
    "    \"\"\" Classify type of document from list of entities(NLU + Configuration file)\n",
    "    \"\"\"\n",
    "    e= dict()\n",
    "    entities_req= entities_required_classification(text,config)\n",
    "    for i in range(len(entities_req)):\n",
    "        temp= list()\n",
    "        for j in range(len(entities_req[i])):\n",
    "            entities_req[i][j][0]= entities_req[i][j][0].strip()\n",
    "            entities_req[i][j][0]= entities_req[i][j][0].lower()\n",
    "            temp.append(entities_req[i][j][0])\n",
    "            res= analyze_using_NLU(text)\n",
    "            #temp= temp + res\n",
    "            #print text\n",
    "            #text= text.decode('utf-8')\n",
    "        if all(str(x) in text.lower() for x in temp) and any(str(y) in text.lower() for y in res):\n",
    "            return entities_req[i][j][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doc_classify(text,config,config1):\n",
    "    \"\"\" Classify type of Document\n",
    "    \"\"\"\n",
    "    entities= analyze_using_NLU(text)\n",
    "    entities.append(extract_entities(config,text))\n",
    "    #print(entities)\n",
    "    entities= [unicode(e).lower() for e in entities]\n",
    "    entities= [e.strip() for e in entities]\n",
    "    entities= set(entities)\n",
    "    ret=classify_text(text,entities,config1)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Rental'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_classify(text2,config,config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
